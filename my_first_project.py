# -*- coding: utf-8 -*-
"""My first Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yOG4gyazSafPlWMN8xxbyGW2Chmjve0A
"""

!pip install psycopg2-binary sqlalchemy==1.4.47 ipython-sql==0.4.1

# Commented out IPython magic to ensure Python compatibility.
# %load_ext sql

# Commented out IPython magic to ensure Python compatibility.
# %%sql
# 
# SELECT * FROM ds_salaries;

import os
import pandas as pd
import sqlalchemy as sql
import matplotlib.pyplot as plt

os.environ["DATABASE_URL"] = "postgresql://captmarroyo:v2_3uAvV_vFYzpBDytViYWU6RBVLBbJU@db.bit.io/captmarroyo/coopdataanalytics"
# Creating engine to connect to database w/ Python
engine = sql.create_engine(os.environ["DATABASE_URL"])

query = "SELECT * FROM ds_salaries"
my_query_df = pd.read_sql(query, con=engine)

# Getting the data from the database into a DataFrame
ds_salaries = pd.read_sql("SELECT * FROM ds_salaries", con=engine)
countries = pd.read_sql("SELECT * FROM countries", con=engine)
usd_exchange_rates = pd.read_sql("SELECT * FROM usd_exchange_rates", con=engine)
experience_levels = pd.read_sql("SELECT * FROM experience_levels", con=engine)
employment_types = pd.read_sql("SELECT * FROM employment_types", con=engine)

ds_salaries_clean = ds_salaries.copy()

ds_salaries_clean.head()

ds_salaries_clean.info()

#Count of NUll values
ds_salaries_clean.isna().sum()

ds_salaries_clean = ds_salaries_clean.dropna(subset=['salary'])

ds_salaries_clean.isna().sum()

assert ds_salaries_clean.salary.isna().sum() == 0

ds_salaries_clean = ds_salaries_clean.dropna(subset=['company_size'])

assert ds_salaries_clean.company_size.isna().sum() == 0

# Creating a filter for "On-site only" remote ratios
onsite_only = ds_salaries_clean.loc[ds_salaries_clean.remote_ratio == 0]
# Setting the `remote_work_type` values for the data found by the filter to "On-site only"
ds_salaries_clean.loc[onsite_only.index, 'remote_work_type'] = 'On-site only'

hybrid = ds_salaries_clean.loc[ds_salaries_clean.remote_ratio == 50]
ds_salaries_clean.loc[hybrid.index, 'remote_work_type'] = 'Hybrid'

fully_remote = ds_salaries_clean.loc[ds_salaries_clean.remote_ratio == 100]
ds_salaries_clean.loc[fully_remote.index, 'remote_work_type'] = 'Fully remote'

# There are no nulls in remote_work_type
assert ds_salaries_clean.remote_work_type.isna().sum() == 0
# The values in remote_work_type were created correctly
values = list(ds_salaries_clean.remote_work_type.unique())
values_check = ['On-site only', 'Fully remote', 'Hybrid']
assert  len(values) == len(values_check) and len([i for i in values if i in values_check]) == 3
# There are no more null values in ds_salaries_clean
assert ds_salaries_clean.isna().sum().sum() == 0

usd_exchange_rates.head()

df = pd.merge(ds_salaries_clean, usd_exchange_rates, left_on = 'salary_currency', right_on = 'iso_code')

df.loc[:, 'salary_in_usd'] = round(df['salary'] / df['exchange_rate'])

#Merging Datasets
df1 = pd.merge(df, experience_levels, left_on="experience_level", right_on="abbreviation")
df2 = pd.merge(df1, employment_types, left_on="employment_type", right_on="abbreviation")
df3 = pd.merge(df2, countries, left_on="company_location", right_on="abbreviation")
df3.head()

#Dropping unnecessary colums
df4 = df3.drop(["abbreviation_x","abbreviation_y","abbreviation","iso_code","ref_date"],axis = "columns")

dropped_cols = ['abbreviation_x','abbreviation_y', 'abbreviation', 'iso_code', 'ref_date']
assert len([i for i in ds_salaries_clean if i in dropped_cols]) == 0

#Dropping duplicates
ds_salaries_clean = df4.drop_duplicates()

# Testing for null values
assert ds_salaries_clean.isna().sum().sum() == 0
# Testing for duplicates
assert ds_salaries_clean.duplicated().sum() == 0

#Saving the cleaned Dataset into a csv file
ds_salaries_clean.to_csv("ds_salaries_clean.csv", index=False)

#The average overall salary (regardless of year) by job category
sal_by_job_cat = ds_salaries_clean.loc[:, ["job_category", "salary_in_usd"]]
sal_by_job_cat.groupby(['job_category']).mean().sort_values(['salary_in_usd'], ascending = False).round()

#The average salary by job category and experience level (regardless of year)
sal = ds_salaries_clean.loc[:, ["job_category","experience_level_description", "salary_in_usd"]]
sal.groupby(['job_category', 'experience_level_description']).mean().sort_values(['salary_in_usd'], ascending = False).round()

#Which country do data analysts make the most money on average and Which country do they make the least
df=ds_salaries_clean.loc[:,['job_category','country_name','salary_in_usd']]
df[df["job_category"] == "Data Analyst"].groupby(['country_name']).mean().sort_values(['salary_in_usd'], ascending = False).round()

#Which job category earns more on average: Data Analyst, Data Science, or Data Engineering
df=ds_salaries_clean.loc[:,['job_category','salary_in_usd']]
df[df['job_category'].isin(["Data Analyst", "Data Science", "Data Engineering"])].groupby(['job_category']).mean().round()

#Which company size pays data professionals the most on average and Is there a relationship between company size and average pay
ds_salaries_clean.loc[:, ['company_size','salary_in_usd']].groupby(['company_size']).mean().round()

#Which job category pays the most on average in 2022
df=ds_salaries_clean.loc[:,['job_category','work_year','salary_in_usd']]
df[df["work_year"] == 2022 ].groupby(['job_category']).mean().sort_values(['salary_in_usd'], ascending = False).round()

#How are companies working in 2022 (Remote, In-Office, Hybrid)
df=ds_salaries_clean.loc[:,['remote_work_type','work_year']]
df[df["work_year"] == 2022 ].groupby(['remote_work_type']).count()

#Pie Chart for Companies work types in 2022
df = ds_salaries_clean.loc[:,['remote_work_type','work_year']]
data = df[df["work_year"] == 2022]
counts = data.groupby(['remote_work_type']).count()
explode = (0, 0.2, 0)
plt.title("Companies Work types in 2022")
plt.pie(counts['work_year'], explode = explode, labels=counts.index, autopct='%0.1f%%', shadow=True, startangle=60)
plt.show()

#Line Chart on Average Salary for Data Analysts by Country
data = ds_salaries_clean[ds_salaries_clean["job_category"] == "Data Analyst"]
means = data.groupby(['country_name'])['salary_in_usd'].mean()
means = means.sort_values(ascending=False)
means = means.round()
means.plot(kind='line', color='green', marker='o')
plt.title('Average Salary for Data Analysts by Country')
plt.xlabel('Country')
plt.ylabel('Salary in USD')
plt.xticks(range(len(means.index)), means.index, rotation=90)
plt.grid()
plt.show()

#Bar Chart on Avarege Salary by job category
means = ds_salaries_clean.groupby(['job_category'])['salary_in_usd'].mean()
means = means.sort_values(ascending=False)
means = means.round()
means.plot(kind='barh', color='green')
plt.title('Average Salary by Job Category')
plt.xlabel('Salary in USD')
plt.ylabel('Job Category')
plt.grid()
plt.show()